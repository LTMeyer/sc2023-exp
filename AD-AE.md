# Artifact Description

## Artifact Identification

High Throughput Training of Deep Surrogates from Large Ensemble Runs

by Lucas Meyer (1, 2), Marc Schouler (1), Robert Alexander Caulk (1), Alejandro Ribes (2), and Bruno Raffin (1)
from (1) Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, Grenoble, France, and (2) Industrial AI Laboratory SINCLAIR, EDF Lab
Paris-Saclay, Palaiseau, France

The paper presents a framework that enables the online training of deep surrogate models on massive simulation datasets. The framework circumvents I/O bottlenecks by streaming directly synthetic data generated by iterative solvers of partial differential equations to the artificial neural network for training. To provide a high throughput the framework leverages several levels of parallelism. The solver code is executed on several cores. Multiple instances of the solver are run in parallel. Generated data are distributed over multiple GPUs in a data-distributed pattern. The framework provides a training reservoir that mitigates the bias inherent to the online learning setting. Additionally, the framework is fault-tolerant and elastic.

## Experiment Reproducibility

%START_LATEX
The experiment workflow is thoroughly detailed in the dedicated repository\footnote{\url{https://gitlab.inria.fr/melissa/sc2023/}} which contains the configuration files used for the experiments presented in the paper, the obtained results with the scripts to generate the plots, and similar configuration files to reproduce the experiments at a smaller scale. The steps to run these smaller-scale experiments are summarized below. A larger-scale experiment can also be run by following the same workflow but with the configuration files used for the actual experiments presented in the paper.
%STOP_LATEX

The experiments compare the training of the deep surrogate for the heat equation with different settings (offline and online) and different reservoir implementations. First, the framework must be installed. The repository contains guidelines to do so. The solver of the heat equation must be compiled with the installed API. Second, the offline data required for comparison must be generated. The framework is run twice to generate the training and validation datasets respectively. Here data are written on disk while in its intended use the framework would directly stream data to the server. Once generated, the raw data must be processed. A Python script compresses these data and allows faster loading during the training of the network. Another Python script achieves offline training on the generated data. Third, the framework configuration is adapted to achieve the training online. Three runs must be executed for the three different implementations of the training reservoir. Finally, the post-processing steps consist in gathering all the tensorboards generated by the 4 runs (1 offline and 3 online). Two Python scripts are provided to plot the throughput and the training losses from the tensorboards.

Moreover, the same Python scripts and the result data that have been used to generate the plots presented in the article are provided.

The total running time of the experiment takes between 1 and 2 hours, with the compilation and installation taking most of the time. Note that the installation of the framework is fast compared to the installation of a Python virtual environment containing a deep learning framework (Pytorch) required for training.

The experiments generate similar plots to the ones presented in the article. These plots are the support to validate the reproducibility of the experimental results. The first plot shows the evolution of the throughput and the population for the different implementations of the training reservoir. It is expected that the Reservoir provides the highest throughput compared to the FIFO and FIRO implementations. For these two latter implementations, the population is expected to stay constant. The trend of this smaller-scale experiment should match the trend displayed in Figure 2 of the article. The second plot shows the training and validation losses for the 4 different experiments. FIFO validation loss is expected to be much higher than the 3 others, indicating detrimental over-fitting. The Reservoir loss is expected to go for more batches and to reach lower values.

The small-scale experiment should already highlight the results presented in the article that the proposed framework and Reservoir implementation provide high throughput and lower validation loss.

# Artifact Evaluation

## Artifact Dependencies and Requirements

To ease reproduction on any machine, the proposed experiment requires 4 cores. However, the experiments achieved at the scale presented in the paper require access to GPUs beside multiple cores. 

The framework has been designed to work with Unix operating systems. It relies on Python for its core and C for the API. The API and the example that consists of a heat equation solver written in C must be compiled. The transfer of the data between the clients and the server requires the installation of ZMQ. The Python core of the framework requires common Python packages, especially for deep learning like Pytorch. The dependency is listed in a dedicated `requirements.txt` file.

The whole purpose of the framework is to generate the dataset along with the training itself. As such no input dataset is required as it will be generated during the experiment.

## Artifact Installation & Deployment Process

%START_LATEX
The artifact provides a ReadMe file with guidelines about the installation of the framework, the compilation of the simulation and the running of the small-scale experiments. The command in the ReadMe can be followed as they are. Only 2 files must be edited to reflect specific user paths. The framework is open source\footnote{\url{https://joss.theoj.org/papers/10.21105/joss.05291}} and the exact tagged version used for the paper experiments can be cloned from git\footnote{\url{https://gitlab.inria.fr/melissa/melissa/-/tree/SC23?ref_type=tags}}.
%STOP_LATEX

The experiments presented in the paper are achieved at a scale that requires thousands of cores and multiple GPUs. The artifact also contains the running scripts, the results and the plotting scripts of these experiments. The ReadMe includes guidelines about how to reproduce the figures from the provided results.